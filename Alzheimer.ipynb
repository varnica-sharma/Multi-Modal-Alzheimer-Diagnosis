{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15259ac5",
   "metadata": {},
   "source": [
    "# Multi-Modal Graph Learning for Alzheimer's Diagnosis\n",
    "\n",
    "This notebook loads the enriched ADNI tables, trains the weighted GCN, and surfaces evaluation, interpretability, and inference workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f449ca",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from alzheimer_pipeline import (\n",
    "    prepare_dataset,\n",
    "    train_gcn,\n",
    "    summarise_performance,\n",
    "    confusion_matrix_split,\n",
    "    save_artifacts,\n",
    "    explain_nodes,\n",
    "    compute_subgroup_metrics,\n",
    "    predict_patient,\n",
    "    LABEL_NAMES,\n",
    ")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be136b",
   "metadata": {},
   "source": [
    "## 2. Build the Patient Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c20345",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"Datasets\")\n",
    "artifacts = prepare_dataset(DATA_DIR, k_neighbors=20, seed=SEED)\n",
    "data = artifacts.data\n",
    "patient_df = artifacts.patient_table.copy()\n",
    "patient_df[\"Diagnosis\"] = patient_df[\"Label\"].map(LABEL_NAMES)\n",
    "\n",
    "print(f\"Total baseline visits: {len(patient_df):,}\")\n",
    "print(\"Class distribution:\")\n",
    "display(patient_df[\"Diagnosis\"].value_counts().rename_axis(\"Diagnosis\").to_frame(\"Count\"))\n",
    "\n",
    "missing_rates = patient_df[artifacts.feature_columns].isna().mean().sort_values(ascending=False)\n",
    "print(\"Feature missingness (top 10):\")\n",
    "display(missing_rates.head(10).to_frame(\"Missing Rate\").style.format({\"Missing Rate\": \"{:.1%}\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a42a41",
   "metadata": {},
   "source": [
    "## 3. Train the GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_gcn(data, epochs=400, patience=60, lr=5e-4)\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed07d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(history_df[\"epoch\"], history_df[\"train_acc\"], label=\"Train\")\n",
    "axes[0].plot(history_df[\"epoch\"], history_df[\"val_acc\"], label=\"Validation\")\n",
    "axes[0].set_title(\"Accuracy vs. Epoch\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history_df[\"epoch\"], history_df[\"val_loss\"], color=\"tab:red\")\n",
    "axes[1].set_title(\"Validation Loss\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc41a0",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6305ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = summarise_performance(model, data)\n",
    "for split, metrics in reports.items():\n",
    "    print(f\"{split.upper()} classification report\")\n",
    "    display(pd.DataFrame(metrics).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c348535",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix_split(model, data, split=\"test\")\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(LABEL_NAMES.values())).plot(\n",
    "    cmap=\"Blues\", values_format=\"d\"\n",
    ")\n",
    "plt.title(\"Test Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d03e47",
   "metadata": {},
   "source": [
    "## 5. Subgroup Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_with_bins = patient_df.copy()\n",
    "age_bins = pd.cut(patient_with_bins[\"Age\"], bins=[45, 55, 65, 75, 85, 100], right=False, labels=[\"45-54\", \"55-64\", \"65-74\", \"75-84\", \"85+\"])\n",
    "patient_with_bins[\"AgeBin\"] = age_bins\n",
    "patient_with_bins[\"APOE4Carrier\"] = (patient_with_bins.get(\"APOE4Count\", 0) >= 1).astype(int)\n",
    "\n",
    "print(\"Gender breakdown\")\n",
    "display(compute_subgroup_metrics(model, data, patient_with_bins, split=\"test\", group_by=[\"GenderBinary\"]))\n",
    "\n",
    "print(\"APOE4 carrier breakdown\")\n",
    "display(compute_subgroup_metrics(model, data, patient_with_bins, split=\"test\", group_by=[\"APOE4Carrier\"]))\n",
    "\n",
    "print(\"Age bin breakdown\")\n",
    "display(compute_subgroup_metrics(model, data, patient_with_bins, split=\"test\", group_by=[\"AgeBin\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f679d8c",
   "metadata": {},
   "source": [
    "## 6. Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.where(data.test_mask.cpu().numpy())[0]\n",
    "np.random.seed(SEED)\n",
    "selected_nodes = np.random.choice(test_indices, size=min(3, len(test_indices)), replace=False)\n",
    "explanations = explain_nodes(model, data, artifacts, selected_nodes, top_k=5)\n",
    "\n",
    "for node, details in explanations.items():\n",
    "    print(f\"Node {node} | RID {int(artifacts.patient_table.iloc[node]['RID'])} | Diagnosis {LABEL_NAMES[int(artifacts.patient_table.iloc[node]['Label'])]}\")\n",
    "    top_features = sorted(details[\"feature_attributions\"].items(), key=lambda kv: abs(kv[1]), reverse=True)[:5]\n",
    "    print(\"  Top feature contributions:\")\n",
    "    for feature, score in top_features:\n",
    "        print(f\"    {feature}: {score:.3f}\")\n",
    "    print(\"  Modality attribution:\")\n",
    "    for modality, score in details[\"modality_attributions\"].items():\n",
    "        print(f\"    {modality}: {score:.2f}\")\n",
    "    print(\"  Nearest neighbours:\")\n",
    "    for neighbour in details[\"nearest_neighbors\"][:3]:\n",
    "        print(f\"    RID {neighbour['RID']} ({neighbour['Diagnosis']}) | distance={neighbour['distance']:.3f}\")\n",
    "    print(\"-\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c859ee6",
   "metadata": {},
   "source": [
    "## 7. Example Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008219e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row = patient_df.sample(1, random_state=SEED).iloc[0]\n",
    "input_features = example_row[artifacts.feature_columns].to_dict()\n",
    "result = predict_patient(\n",
    "    model.cpu(),\n",
    "    data,\n",
    "    artifacts.preprocessor,\n",
    "    artifacts.neighbor_model,\n",
    "    artifacts.modality_processors,\n",
    "    artifacts.modality_weights,\n",
    "    artifacts.distance_scale,\n",
    "    artifacts.feature_columns,\n",
    "    input_features,\n",
    "    patient_table=artifacts.patient_table,\n",
    "    return_explanations=True,\n",
    ")\n",
    "print(\"Probabilities:\", result[\"probabilities\"])\n",
    "print(\"Modality contributions:\", result[\"modality_contributions\"])\n",
    "print(\"Nearest neighbours:\")\n",
    "for neighbour in result[\"nearest_neighbors\"][:5]:\n",
    "    print(neighbour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a7cd5",
   "metadata": {},
   "source": [
    "## 8. Persist Artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325df508",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_DIR = Path(\"artifacts\")\n",
    "save_artifacts(ARTIFACT_DIR, artifacts, model, history)\n",
    "print(f\"Saved artefacts to {ARTIFACT_DIR.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
